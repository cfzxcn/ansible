- name: 添加EPEL仓库
#  copy: src="/root/playbook/roles/php/files/epel.repo" dest=/etc/yum.repos.d/epel.repo
  copy: src="../../php/files/epel.repo" dest=/etc/yum.repos.d/epel.repo

- name: Generate andy's ssh-keygen
  shell: '[ -f ~/.ssh/id_rsa ] || ssh-keygen -t rsa -q -N "" -f ~/.ssh/id_rsa'

- name: ssh-copy-id to all ceph node
  shell: 'for i in controller compute1 pxc1 pxc2 c1 c4 c6 c7 c8;do sshpass -pcf ssh-copy-id -o strictHostkeychecking=no $i;done'
#  shell: 'for i in 30 61 64 66 67 68;do sshpass -pcf ssh-copy-id -o strictHostkeychecking=no andy@192.168.1.$i;done'

#- name: yum install python-setuptools
#  yum: name="python-setuptools"
# 安装ceph-deploy 开始
- name: controller ceph-deploy tasts
  block:
    - name: yum install ceph-deploy
      yum: name='ceph-deploy'

    - name: mkdir ceph-cluster
      file: "path={{ cephDir }} state=directory"
#- name: ceph-deploy install --no-adjust-repos controller compute1 pxc1 pxc2 c1 c4 c6 c7 c8 安装ceph软件包
#  shell: cd {{ cephDir }} && ceph-deploy install --no-adjust-repos controller compute1 pxc1 pxc2 c1 c4 c6 c7 c8
#  tags: deployinstall
# 安装ceph-deploy 结束
    - name: copy ceph.conf to {{ cephDir }}
      copy: src=ceph.conf dest={{ cephDir }}
    
    - name: ceph-deploy mon create-initial
      shell: 'cd {{ cephDir }} && ceph-deploy --overwrite-conf mon create-initial'
    #  shell: cd {{ cephDir }} && ceph-deploy new --cluster-network 60.0.0.0/24 --public-network 192.168.1.0/24 c1:c1.st.cn
    # 哪些node作为monitor node，在ceph.conf中指定

    - name: ceph-deploy rgw create c1
      shell: 'cd {{ cephDir }} && ceph-deploy rgw create c1'
    # 增加对象存储网关（rgw/radosgw）
    
    - name: ceph-deploy admin controller compute1 pxc1 pxc2 c1 c4 c6 c7 c8
      shell: 'cd {{ cephDir }} && ceph-deploy --overwrite-conf admin controller compute1 pxc1 pxc2 c1 c4 c6 c7 c8'
    # 用Ceph -deploy将配置文件和管理密钥复制到您的管理节点和Ceph节点
    
    - name: ceph config set mon auth_allow_insecure_global_id_reclaim false
      shell: 'cd {{ cephDir }} && ceph config set mon auth_allow_insecure_global_id_reclaim false'
    # 避免ceph -s出现：mons are allowing insecure global_id reclaim
    
    - name: ceph-deploy mgr create c4
      shell: 'cd {{ cephDir }} && ceph-deploy --overwrite-conf mgr create c4'
    # 部署manager node
    
    #- name: ceph-deploy osd create
#  shell: 'cd {{ cephDir }};for i in 6 7 8;do ceph-deploy osd create --data /dev/sdb c$i;ceph-deploy osd create --data /dev/sdc c$i;done'
#  ignore_errors: yes

    - name: ceph-deploy mds create c1
      shell: 'cd {{ cephDir }} && ceph-deploy --overwrite-conf mds create c1'
  when: ansible_fqdn == 'controller'
# 添加元数据服务器（mds主要用在cephfs场景，文件存储元数据信息）

# 运行仪表板准备开始
#- name: ceph-deploy --overwrite-conf config push c4
#  shell: ceph-deploy --overwrite-conf config push c4
- name: Setup dashboard on c4
  block:
    - name: yum install ceph-mgr-dashboard to c4
      yum: name=ceph-mgr-dashboard
    
    - name: ceph mgr module enable dashboard
      shell: 'ceph mgr module enable dashboard'
    
    - name: ceph dashboard create-self-signed-cert
      shell: 'ceph dashboard create-self-signed-cert'
    
    - name: ceph config set mgr mgr/dashboard/ssl true
      shell: 'ceph config set mgr mgr/dashboard/ssl true'

    - name: systemctl restart ceph-mgr@c4.service
      service: name=ceph-mgr@c4.service state=restarted

    - name: Generate dashboard passwd file
      copy: content="cf" dest=/etc/ceph/pass

    - name: ceph dashboard ac-user-create admin administrator -i /etc/ceph/pass
      shell: 'ceph dashboard ac-user-create admin administrator -i /etc/ceph/pass'
  when: ansible_fqdn == 'c4.st.cn'
# 运行仪表板准备结束

- name: Create replicated pools
  ignore_errors: true
  block:
    - name: ceph osd pool create volumes 256 && ceph osd pool application enable volumes rbd
      shell: 'ceph osd pool create volumes 256 && ceph osd pool application enable volumes rbd'
    
    - name: ceph osd pool create vms 256 && ceph osd pool application enable vms rbd
      shell: 'ceph osd pool create vms 256 && ceph osd pool application enable vms rbd'

    - name: client.cinder authentication
      shell: "ceph auth get-or-create client.cinder mon 'profile rbd' osd 'profile rbd pool=volumes,profile rbd pool=vms' > /etc/ceph/ceph.client.cinder.keyring"

    - name: rbd create volumes/disk1 --size 25G && rbd create vms/disk2 --size 20G
      shell: 'rbd create volumes/disk1 --size 25G && rbd create vms/disk2 --size 20G'

    - name: Disable volumes/disk1 and vms/disk2 exclusive-lock object-map fast-diff deep-flatten
      shell: 'rbd feature disable volumes/disk1 exclusive-lock object-map fast-diff deep-flatten && rbd feature disable vms/disk2 exclusive-lock object-map fast-diff deep-flatten'

    - name: copy /etc/ceph/ceph.client.cinder.keyring to other node
      shell: 'for i in compute1 pxc1 pxc2 c1 c4 c6 c7 c8;do scp /etc/ceph/ceph.client.cinder.keyring $i:/etc/ceph;done'
#    - name: map rbd
#      lineinfile:
#        dest: /etc/ceph/rbdmap
#        line: "volumes/disk1 id=cinder,keyring=/etc/ceph/ceph.client.cinder.keyring"
#        backup: true

    - name: chown cinder:cinder /etc/ceph/ceph.client.cinder.keyring
      file: 
        path: /etc/ceph/ceph.client.cinder.keyring
        owner: cinder
        group: cinder
#  when: ansible_fqdn == 'controller' or ansible_fqdn == 'compute1'
    - name: Generate uuid
      shell: "uuidgen > /etc/ceph/uuid.txt"

    - name: Generate /etc/ceph/ceph.xml
      shell:
        cmd: |
          echo -e "\n" > /etc/ceph/ceph.xml
          cat > /etc/ceph/ceph.xml <<EOF
          <secret ephemeral='no' private='no'>
          <uuid>$(cat /etc/ceph/uuid.txt)</uuid>
          <usage type='ceph'>
          <name>client.cinder secret</name>
          </usage>
          </secret>
          EOF
#    - name: copy /etc/ceph/ceph.xml to other compute node
#      shell: 'for i in 2 3 4;do scp /etc/ceph/ceph.xml compute$i:/etc/ceph;done'
  when: ansible_fqdn == 'compute1'

- name: compute set cinder and nova ceph
  ignore_errors: true
  block:
    - name: virsh secret-define --file /etc/ceph/ceph.xml
      shell: "virsh secret-define --file /etc/ceph/ceph.xml"

    - name: virsh secret-set-value --secret $(cat /etc/ceph/uuid.txt) --base64 $(grep key /etc/ceph/ceph.client.cinder.keyring | awk -F ' ' '{ print $3 }')
      shell: "virsh secret-set-value --secret $(cat /etc/ceph/uuid.txt) --base64 $(grep key /etc/ceph/ceph.client.cinder.keyring | awk -F ' ' '{ print $3 }')"

    - name: Babkup {{ cinderConfPath }}
      shell: "cp -a {{ cinderConfPath }}{,.`date +%F.%T`}"

    - name: Modify {{ cinderConfPath }}
      shell: >
        openstack-config --set {{ cinderConfPath }} DEFAULT enabled_backends ceph,lvm &&
        openstack-config --set {{ cinderConfPath }} ceph volume_driver cinder.volume.drivers.rbd.RBDDriver &&
        openstack-config --set {{ cinderConfPath }} ceph volume_backend_name ceph &&
        openstack-config --set {{ cinderConfPath }} ceph rbd_pool volumes &&
        openstack-config --set {{ cinderConfPath }} ceph rbd_ceph_conf /etc/ceph/ceph.conf &&
        openstack-config --set {{ cinderConfPath }} ceph rbd_flatten_volume_from_snapshot false &&
        openstack-config --set {{ cinderConfPath }} ceph rbd_max_clone_depth 5 &&
        openstack-config --set {{ cinderConfPath }} ceph rbd_store_chunk_size 4 &&
        openstack-config --set {{ cinderConfPath }} ceph rados_connect_timeout -1 &&
        openstack-config --set {{ cinderConfPath }} ceph glance_api_version 2 &&
        openstack-config --set {{ cinderConfPath }} ceph rbd_user cinder &&
        openstack-config --set {{ cinderConfPath }} ceph rbd_secret_uuid $(cat /etc/ceph/uuid.txt)

    - name: Babkup {{ novaConfPath }}
      shell: "cp -a {{ novaConfPath }}{,.`date +%F.%T`}"

    - name: Modify {{ novaConfPath }}
      shell: >
#       "openstack-config --set {{ novaConfPath }} DEFAULT live_migration_flag VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE,VIR_MIGRATE_PERSIST_DEST,VIR_MIGRA TE_TUNNELLED" &&
#        "openstack-config --set {{ novaConfPath }} libvirt 'inject_partition -2'" &&
        openstack-config --set {{ novaConfPath }} libvirt images_type rbd &&
        openstack-config --set {{ novaConfPath }} libvirt images_rbd_pool vms &&
        openstack-config --set {{ novaConfPath }} libvirt images_rbd_ceph_conf /etc/ceph/ceph.conf &&
#        openstack-config --set {{ novaConfPath }} libvirt disk_cachemodes network=writeback &&
        openstack-config --set {{ novaConfPath }} libvirt rbd_user cinder &&
        openstack-config --set {{ novaConfPath }} libvirt rbd_secret_uuid $(cat /etc/ceph/uuid.txt)

    - name: computes restart cinder and nova
      shell: "openstack-service restart cinder && openstack-service restart nova"
  when: ansible_fqdn == 'compute1' 
#  when: ansible_fqdn == 'compute1' or ansible_fqdn == 'compute2'

- name: controller set cinder and nova ceph
  ignore_errors: true
  block:
    - name: cinder type-create ceph
      shell: "cinder type-list | grep ceph &>/dev/null || cinder type-create ceph"

    - name: cinder type-key ceph set volume_backend_name=ceph
      shell: "cinder extra-specs-list | grep ceph &>/dev/null || cinder type-key ceph set volume_backend_name=ceph"
#    - name: Append 'default_volume_type = ceph,lvm' to {{ cinderConfPath }}
#      lineinfile:
#        path: "{{ cinderConfPath }}"
#        insertafter="[DEFAULT]"
#        line='default_volume_type = ceph,lvm'
#        backup=true
#      notify: restart cinder
    - name: controller restart cinder and nova
      shell: "openstack-service restart cinder && openstack-service restart nova"
  when: ansible_fqdn == 'controller'











